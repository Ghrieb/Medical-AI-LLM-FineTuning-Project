# Model Evaluation Notebook

## Overview:
This notebook demonstrates the evaluation of the pre-trained **Meta Llama 2** model deployed on **AWS SageMaker**. The objective was to assess the model's ability to generate contextually relevant text related to **genomic characterization** in the medical field.

### Evaluation Steps:
1. **Model Deployment**: The Meta Llama 2 model was deployed using SageMaker.
2. **Input Prompt**: Medical-related prompts were provided to test the model's general knowledge before fine-tuning.
3. **Model Output**: Screenshots of the model's output are provided below, showcasing how the pre-trained model performed.

![Pre-Tuned Model Output](../results/pre_tuned_output.png)

### Conclusion:
The pre-trained model provided generic responses related to the medical domain. However, its output lacked specificity in areas such as **viral genomics** and **genomic research**, which prompted the fine-tuning phase to improve the model's relevance.

# Notice
I have been granted permission to share this project publicly. However, detailed code implementations and proprietary instructions provided by Udacity and AWS have been omitted in this public version of the project.
